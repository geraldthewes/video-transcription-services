# Use an official Python runtime as a parent image
FROM python:3.12

# Set the working directory in the container
WORKDIR /app

# Copy requirements file first for better Docker layer caching
COPY requirements.txt /app/

# Install any needed packages
# Keeping dependencies consistent with the main app for shared modules, even if not all are strictly used by the worker.
RUN pip install --no-cache-dir -r requirements.txt

# Copy the local directory contents into the container at /app
# This will copy the entire transcriber_service package
COPY ./transcriber_service /app/transcriber_service


# Define environment variable for Python path if necessary, though direct app path usually works.
# ENV PYTHONPATH "${PYTHONPATH}:/app"

# Command to run the Celery worker
# -A: Application instance
# worker: The worker subcommand
# -l: Logging level
# -P: Concurrency pool (solo is simple, processes one task at a time in the main process)
# Consider 'gevent' or 'eventlet' for I/O bound tasks if 'solo' is too limiting,
# but 'solo' is often recommended for CPU-bound or GPU-bound tasks to avoid contention.
CMD ["celery", "-A", "transcriber_service.tasks.transcription.celery_app", "worker", "-l", "INFO", "-P", "solo"]
